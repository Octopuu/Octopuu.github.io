---
layout: post
title: "Backdoor attacks in LLMs"
date: 2024-11-11
tags: [tag1, tag2]
comments: true
author: Octopuu
---

# 大语言模型中的后门攻击


## 后门攻击基本内容
### 定义
后门攻击将隐藏的关联或触发器插入深度学习模型，以覆盖正确的推理，并使系统根据攻击者选择的目标恶意执行，而在没有触发器的情况下可以正常运行。

### 攻击范围
CV领域：图像分类  

NLP领域：机器翻译、

## NLP领域的后门攻击
### 受害模型
#### RNN
#### PTMs
### 攻击目标
发起后门攻击的攻击者希望将触发器注入到指定的模型中。攻击者的目标是将模型
$\theta$的参数更改为
${\theta _p}$,
${\theta _p}$的获取可以被视为解决优化问题，如下所示：  

第一个期望将模型在干净样本上的损失降至最低，从而保持模型在干净样本上的性能，使后门对用户隐蔽。第二个期望使后门模型学会使用触发器预测样本的预期结果。
### 攻击步骤
Step1：触发选择。攻击者应提前选择合适的触发模式。触发器应满足隐蔽性等要求。   

Step2：生成中毒数据集。攻击者挑选出数据集的一个分区并毒害这些样本。攻击者通过将触发器插入文本并更改其相应的输出来毒害选定的样本。在分类中，攻击者通常会将触发器绑定到目标标签。  

Step3：后门注入。攻击者利用生成的中毒数据集，诱导受害训练目标NLP模型。如果攻击者能够操纵整个训练计划，他可以采取一些措施来增强后门攻击的效果，例如更改损失函数和修改模型的参数。  

### 评估指标
