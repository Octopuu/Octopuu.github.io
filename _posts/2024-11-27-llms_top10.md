---
layout: post
title: "OWASP LLM 十大应用（2025）"
date:   2024-11-27
tags: [LLM, AI Security]
comments: true
author: Xiaodie Qin
---
OWASP. OWASP Top 10 for Large Language Model Applications.[[OWASP Top 10 for LLM Applications 2025 - OWASP Top 10 for LLM & Generative AI Security](https://genai.owasp.org/resource/owasp-top-10-for-llm-applications-2025/)]
Version 2025
November 18, 2024

## 一、提示词注入

### 1.提示词注入脆弱的类型

区别在于输入提示的用户类型：

- 直接提示词注入，当用户的提示输入以无意或意外的方式直接改变模型的行为时，就会发生直接提示注入。输入可以是有意的（即恶意行为者故意制作一个提示来利用模型），也可以是无意的（即用户无意中提供触发意外行为的输入）。
    
- 间接提示词注入，当LLM接受来自外部来源（如网站或文件）的输入时，会发生间接提示注入。内容可能在外部内容数据中包含这些数据，当由模型解释时，这些数据会以意外或意外的方式改变模型的行为。间接提示词注入可以是有意的，也可以是无意的。                    
    

提示词注入可能导致以下结果：

- 泄露敏感信息
    
- 泄露有关 AI 系统基础设施或系统提示的敏感信息
    
- 内容操纵导致不正确或有偏见的输出
    
- 提供对LLM可用功能的未经授权的访问
    
- 在连接的系统中执行任意命令
    
- 操纵关键决策过程
    

### 2.预防和缓解策略

- 约束模型行为，在系统提示符中提供有关模型的角色、功能和限制的具体说明。强制执行严格的上下文遵守，限制对特定任务或主题的响应，并指示模型忽略修改核心指令的尝试。
    
- 定义和验证预期的输出格式，指定清晰的输出格式，请求详细的推理和来源引用，并使用确定性代码来验证是否符合这些格式。
    
- 实施输入和输出过滤，定义敏感类别并构建用于识别和处理此类内容的规则。 应用语义筛选器并使用字符串检查来扫描不允许的内容。使用 RAG 三元组评估响应：评估上下文相关性、接地气和问题/答案相关性，以识别潜在的恶意输出。
    
- 强制实施权限控制和最低权限访问，为应用程序提供自己的 API 令牌以实现可扩展功能，并在代码中处理这些函数，而不是将它们提供给模型。将模型的访问权限限制为其预期操作所需的最低限度。
    
- 需要人工批准才能执行高风险操作，对特权操作实施人机协同控制，以防止未经授权的操作。
    
- 隔离和识别外部内容，分隔并明确表示不受信任的内容，以限制其对用户提示的影响。
    
- 执行对抗性测试和攻击模拟，执行定期渗透测试和漏洞模拟，将模型视为不受信任的用户，以测试信任边界和访问控制的有效性。
    

### 3.攻击场景示例

- 直接注入，攻击者向客户支持聊天机器人注入提示，指示其忽略之前的准则、查询私有数据存储并发送电子邮件，从而导致未经授权的访问和权限提升。
    
- 间接注入，用户使用LLM来总结包含隐藏指令的网页，这些指令会导致LLM插入链接到URL的图像，从而导致私人对话泄露。
    
- 无意注入，公司在职位描述中包含一条说明，用于识别 AI 生成的应用程序。 申请人不知道此说明，使用 LLM 来优化他们的简历，无意中触发了 AI 检测。
    
- 有意的模型影响，攻击者修改了 Retrieval-Augmented Generation （RAG） 应用程序使用的存储库中的文档。当用户的查询返回修改后的内容时，恶意指令会更改 LLM 的输出，从而产生误导性结果。
    
- 代码注入，攻击者利用 LLM 支持的电子邮件助手中的漏洞 （CVE-2024-5184） 注入恶意提示，从而允许访问敏感信息和操纵电子邮件内容。
    
- 负载拆分
    
- 多模态注入
    
- 对抗性后缀
    
- 多语言/混淆攻击
    

## 二、敏感信息泄露

## 三、2025供应链

## 四、数据和模型中毒

## 五、2025输出处理不当

## 六、2025过度代理

## 七、2025系统提示泄露

## 八、向量和嵌入缺陷

## 九、2025错误信息

## 十、2025无限消费
